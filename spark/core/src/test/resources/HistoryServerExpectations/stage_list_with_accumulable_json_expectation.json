[ {
  "status" : "COMPLETE",
  "stageId" : 0,
  "attemptId" : 0,
  "numTasks" : 8,
  "numActiveTasks" : 0,
  "numCompleteTasks" : 8,
  "numFailedTasks" : 0,
  "numKilledTasks" : 0,
  "numCompletedIndices" : 8,
  "submissionTime" : "2015-03-16T19:25:36.103GMT",
  "firstTaskLaunchedTime" : "2015-03-16T19:25:36.515GMT",
  "completionTime" : "2015-03-16T19:25:36.579GMT",
  "executorDeserializeTime" : 102,
  "executorDeserializeCpuTime" : 0,
  "executorRunTime" : 120,
  "executorCpuTime" : 0,
  "resultSize" : 5576,
  "jvmGcTime" : 0,
  "resultSerializationTime" : 15,
  "memoryBytesSpilled" : 0,
  "diskBytesSpilled" : 0,
  "peakExecutionMemory" : 0,
  "inputBytes" : 0,
  "inputRecords" : 0,
  "outputBytes" : 0,
  "outputRecords" : 0,
  "shuffleRemoteBlocksFetched" : 0,
  "shuffleLocalBlocksFetched" : 0,
  "shuffleFetchWaitTime" : 0,
  "shuffleRemoteBytesRead" : 0,
  "shuffleRemoteBytesReadToDisk" : 0,
  "shuffleLocalBytesRead" : 0,
  "shuffleReadBytes" : 0,
  "shuffleReadRecords" : 0,
  "shuffleWriteBytes" : 0,
  "shuffleWriteTime" : 0,
  "shuffleWriteRecords" : 0,
  "name" : "foreach at <console>:15",
  "details" : "org.apache.spark.rdd.RDD.foreach(RDD.scala:765)\n$line9.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:15)\n$line9.$read$$iwC$$iwC$$iwC.<init>(<console>:20)\n$line9.$read$$iwC$$iwC.<init>(<console>:22)\n$line9.$read$$iwC.<init>(<console>:24)\n$line9.$read.<init>(<console>:26)\n$line9.$read$.<init>(<console>:30)\n$line9.$read$.<clinit>(<console>)\n$line9.$eval$.<init>(<console>:7)\n$line9.$eval$.<clinit>(<console>)\n$line9.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:483)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:852)\norg.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1125)\norg.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:674)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:705)\norg.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:669)",
  "schedulingPool" : "default",
  "rddIds" : [ 0 ],
  "accumulatorUpdates" : [ {
    "id" : 1,
    "name" : "my counter",
    "value" : "5050"
  } ],
  "killedTasksSummary" : { }
} ]

-- Automatically generated by SQLQueryTestSuite
-- Number of queries: 18


-- !query 0
CREATE table  explain_temp1 (key int, val int) USING PARQUET
-- !query 0 schema
struct<>
-- !query 0 output



-- !query 1
CREATE table  explain_temp2 (key int, val int) USING PARQUET
-- !query 1 schema
struct<>
-- !query 1 output



-- !query 2
CREATE table  explain_temp3 (key int, val int) USING PARQUET
-- !query 2 schema
struct<>
-- !query 2 output



-- !query 3
SET spark.sql.codegen.wholeStage = true
-- !query 3 schema
struct<key:string,value:string>
-- !query 3 output
spark.sql.codegen.wholeStage	true


-- !query 4
EXPLAIN FORMATTED
  SELECT key, max(val) 
  FROM   explain_temp1 
  WHERE  key > 0 
  GROUP  BY key 
  ORDER  BY key
-- !query 4 schema
struct<plan:string>
-- !query 4 output
== Physical Plan ==
* Sort (9)
+- Exchange (8)
   +- * HashAggregate (7)
      +- Exchange (6)
         +- * HashAggregate (5)
            +- * Project (4)
               +- * Filter (3)
                  +- * ColumnarToRow (2)
                     +- Scan parquet default.explain_temp1 (1)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,0)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 0))
     
(4) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) HashAggregate [codegen id : 1]
Input: [key#x, val#x]
     
(6) Exchange 
Input: [key#x, max#x]
     
(7) HashAggregate [codegen id : 2]
Input: [key#x, max#x]
     
(8) Exchange 
Input: [key#x, max(val)#x]
     
(9) Sort [codegen id : 3]
Input: [key#x, max(val)#x]


-- !query 5
EXPLAIN FORMATTED
  SELECT key, max(val)
  FROM explain_temp1
  WHERE key > 0
  GROUP BY key
  HAVING max(val) > 0
-- !query 5 schema
struct<plan:string>
-- !query 5 output
== Physical Plan ==
* Project (9)
+- * Filter (8)
   +- * HashAggregate (7)
      +- Exchange (6)
         +- * HashAggregate (5)
            +- * Project (4)
               +- * Filter (3)
                  +- * ColumnarToRow (2)
                     +- Scan parquet default.explain_temp1 (1)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,0)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 0))
     
(4) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) HashAggregate [codegen id : 1]
Input: [key#x, val#x]
     
(6) Exchange 
Input: [key#x, max#x]
     
(7) HashAggregate [codegen id : 2]
Input: [key#x, max#x]
     
(8) Filter [codegen id : 2]
Input     : [key#x, max(val)#x, max(val#x)#x]
Condition : (isnotnull(max(val#x)#x) AND (max(val#x)#x > 0))
     
(9) Project [codegen id : 2]
Output    : [key#x, max(val)#x]
Input     : [key#x, max(val)#x, max(val#x)#x]


-- !query 6
EXPLAIN FORMATTED
  SELECT key, val FROM explain_temp1 WHERE key > 0
  UNION 
  SELECT key, val FROM explain_temp1 WHERE key > 0
-- !query 6 schema
struct<plan:string>
-- !query 6 output
== Physical Plan ==
* HashAggregate (12)
+- Exchange (11)
   +- * HashAggregate (10)
      +- Union (9)
         :- * Project (4)
         :  +- * Filter (3)
         :     +- * ColumnarToRow (2)
         :        +- Scan parquet default.explain_temp1 (1)
         +- * Project (8)
            +- * Filter (7)
               +- * ColumnarToRow (6)
                  +- Scan parquet default.explain_temp1 (5)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,0)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 0))
     
(4) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,0)]
ReadSchema: struct<key:int,val:int>
     
(6) ColumnarToRow [codegen id : 2]
Input: [key#x, val#x]
     
(7) Filter [codegen id : 2]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 0))
     
(8) Project [codegen id : 2]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(9) Union 
     
(10) HashAggregate [codegen id : 3]
Input: [key#x, val#x]
     
(11) Exchange 
Input: [key#x, val#x]
     
(12) HashAggregate [codegen id : 4]
Input: [key#x, val#x]


-- !query 7
EXPLAIN FORMATTED
  SELECT * 
  FROM   explain_temp1 a, 
         explain_temp2 b 
  WHERE  a.key = b.key
-- !query 7 schema
struct<plan:string>
-- !query 7 output
== Physical Plan ==
* BroadcastHashJoin Inner BuildRight (10)
:- * Project (4)
:  +- * Filter (3)
:     +- * ColumnarToRow (2)
:        +- Scan parquet default.explain_temp1 (1)
+- BroadcastExchange (9)
   +- * Project (8)
      +- * Filter (7)
         +- * ColumnarToRow (6)
            +- Scan parquet default.explain_temp2 (5)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 2]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 2]
Input     : [key#x, val#x]
Condition : isnotnull(key#x)
     
(4) Project [codegen id : 2]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) Scan parquet default.explain_temp2 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp2]
PushedFilters: [IsNotNull(key)]
ReadSchema: struct<key:int,val:int>
     
(6) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(7) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : isnotnull(key#x)
     
(8) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(9) BroadcastExchange 
Input: [key#x, val#x]
     
(10) BroadcastHashJoin [codegen id : 2]
Left keys: List(key#x)
Right keys: List(key#x)
Join condition: None


-- !query 8
EXPLAIN FORMATTED
  SELECT * 
  FROM   explain_temp1 a 
         LEFT OUTER JOIN explain_temp2 b 
                      ON a.key = b.key
-- !query 8 schema
struct<plan:string>
-- !query 8 output
== Physical Plan ==
* BroadcastHashJoin LeftOuter BuildRight (8)
:- * ColumnarToRow (2)
:  +- Scan parquet default.explain_temp1 (1)
+- BroadcastExchange (7)
   +- * Project (6)
      +- * Filter (5)
         +- * ColumnarToRow (4)
            +- Scan parquet default.explain_temp2 (3)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 2]
Input: [key#x, val#x]
     
(3) Scan parquet default.explain_temp2 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp2]
PushedFilters: [IsNotNull(key)]
ReadSchema: struct<key:int,val:int>
     
(4) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(5) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : isnotnull(key#x)
     
(6) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(7) BroadcastExchange 
Input: [key#x, val#x]
     
(8) BroadcastHashJoin [codegen id : 2]
Left keys: List(key#x)
Right keys: List(key#x)
Join condition: None


-- !query 9
EXPLAIN FORMATTED
  SELECT * 
  FROM   explain_temp1 
  WHERE  key = (SELECT max(key) 
                FROM   explain_temp2 
                WHERE  key = (SELECT max(key) 
                              FROM   explain_temp3 
                              WHERE  val > 0) 
                       AND val = 2) 
         AND val > 3
-- !query 9 schema
struct<plan:string>
-- !query 9 output
== Physical Plan ==
* Project (4)
+- * Filter (3)
   +- * ColumnarToRow (2)
      +- Scan parquet default.explain_temp1 (1)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), IsNotNull(val), GreaterThan(val,3)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (((isnotnull(key#x) AND isnotnull(val#x)) AND (key#x = Subquery scalar-subquery#x, [id=#x])) AND (val#x > 3))
     
(4) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#x, [id=#x]
* HashAggregate (11)
+- Exchange (10)
   +- * HashAggregate (9)
      +- * Project (8)
         +- * Filter (7)
            +- * ColumnarToRow (6)
               +- Scan parquet default.explain_temp2 (5)


(5) Scan parquet default.explain_temp2 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp2]
PushedFilters: [IsNotNull(key), IsNotNull(val), EqualTo(val,2)]
ReadSchema: struct<key:int,val:int>
     
(6) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(7) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (((isnotnull(key#x) AND isnotnull(val#x)) AND (key#x = Subquery scalar-subquery#x, [id=#x])) AND (val#x = 2))
     
(8) Project [codegen id : 1]
Output    : [key#x]
Input     : [key#x, val#x]
     
(9) HashAggregate [codegen id : 1]
Input: [key#x]
     
(10) Exchange 
Input: [max#x]
     
(11) HashAggregate [codegen id : 2]
Input: [max#x]
     
Subquery:2 Hosting operator id = 7 Hosting Expression = Subquery scalar-subquery#x, [id=#x]
* HashAggregate (18)
+- Exchange (17)
   +- * HashAggregate (16)
      +- * Project (15)
         +- * Filter (14)
            +- * ColumnarToRow (13)
               +- Scan parquet default.explain_temp3 (12)


(12) Scan parquet default.explain_temp3 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp3]
PushedFilters: [IsNotNull(val), GreaterThan(val,0)]
ReadSchema: struct<key:int,val:int>
     
(13) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(14) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(val#x) AND (val#x > 0))
     
(15) Project [codegen id : 1]
Output    : [key#x]
Input     : [key#x, val#x]
     
(16) HashAggregate [codegen id : 1]
Input: [key#x]
     
(17) Exchange 
Input: [max#x]
     
(18) HashAggregate [codegen id : 2]
Input: [max#x]


-- !query 10
EXPLAIN FORMATTED
  SELECT * 
  FROM   explain_temp1 
  WHERE  key = (SELECT max(key) 
                FROM   explain_temp2 
                WHERE  val > 0) 
         OR
         key = (SELECT max(key) 
                FROM   explain_temp3
                WHERE  val > 0)
-- !query 10 schema
struct<plan:string>
-- !query 10 output
== Physical Plan ==
* Filter (3)
+- * ColumnarToRow (2)
   +- Scan parquet default.explain_temp1 (1)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : ((key#x = Subquery scalar-subquery#x, [id=#x]) OR (key#x = Subquery scalar-subquery#x, [id=#x]))
     
===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#x, [id=#x]
* HashAggregate (10)
+- Exchange (9)
   +- * HashAggregate (8)
      +- * Project (7)
         +- * Filter (6)
            +- * ColumnarToRow (5)
               +- Scan parquet default.explain_temp2 (4)


(4) Scan parquet default.explain_temp2 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp2]
PushedFilters: [IsNotNull(val), GreaterThan(val,0)]
ReadSchema: struct<key:int,val:int>
     
(5) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(6) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(val#x) AND (val#x > 0))
     
(7) Project [codegen id : 1]
Output    : [key#x]
Input     : [key#x, val#x]
     
(8) HashAggregate [codegen id : 1]
Input: [key#x]
     
(9) Exchange 
Input: [max#x]
     
(10) HashAggregate [codegen id : 2]
Input: [max#x]
     
Subquery:2 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#x, [id=#x]
* HashAggregate (17)
+- Exchange (16)
   +- * HashAggregate (15)
      +- * Project (14)
         +- * Filter (13)
            +- * ColumnarToRow (12)
               +- Scan parquet default.explain_temp3 (11)


(11) Scan parquet default.explain_temp3 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp3]
PushedFilters: [IsNotNull(val), GreaterThan(val,0)]
ReadSchema: struct<key:int,val:int>
     
(12) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(13) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(val#x) AND (val#x > 0))
     
(14) Project [codegen id : 1]
Output    : [key#x]
Input     : [key#x, val#x]
     
(15) HashAggregate [codegen id : 1]
Input: [key#x]
     
(16) Exchange 
Input: [max#x]
     
(17) HashAggregate [codegen id : 2]
Input: [max#x]


-- !query 11
EXPLAIN FORMATTED
  SELECT (SELECT Avg(key) FROM explain_temp1) + (SELECT Avg(key) FROM explain_temp1)
  FROM explain_temp1
-- !query 11 schema
struct<plan:string>
-- !query 11 output
== Physical Plan ==
* Project (3)
+- * ColumnarToRow (2)
   +- Scan parquet default.explain_temp1 (1)


(1) Scan parquet default.explain_temp1 
Output: []
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
ReadSchema: struct<>
     
(2) ColumnarToRow [codegen id : 1]
Input: []
     
(3) Project [codegen id : 1]
Output    : [(Subquery scalar-subquery#x, [id=#x] + ReusedSubquery Subquery scalar-subquery#x, [id=#x]) AS (scalarsubquery() + scalarsubquery())#x]
Input     : []
     
===== Subqueries =====

Subquery:1 Hosting operator id = 3 Hosting Expression = Subquery scalar-subquery#x, [id=#x]
* HashAggregate (8)
+- Exchange (7)
   +- * HashAggregate (6)
      +- * ColumnarToRow (5)
         +- Scan parquet default.explain_temp1 (4)


(4) Scan parquet default.explain_temp1 
Output: [key#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
ReadSchema: struct<key:int>
     
(5) ColumnarToRow [codegen id : 1]
Input: [key#x]
     
(6) HashAggregate [codegen id : 1]
Input: [key#x]
     
(7) Exchange 
Input: [sum#x, count#xL]
     
(8) HashAggregate [codegen id : 2]
Input: [sum#x, count#xL]
     
Subquery:2 Hosting operator id = 3 Hosting Expression = ReusedSubquery Subquery scalar-subquery#x, [id=#x]


-- !query 12
EXPLAIN FORMATTED
  WITH cte1 AS (
    SELECT *
    FROM explain_temp1 
    WHERE key > 10
  )
  SELECT * FROM cte1 a, cte1 b WHERE a.key = b.key
-- !query 12 schema
struct<plan:string>
-- !query 12 output
== Physical Plan ==
* BroadcastHashJoin Inner BuildRight (10)
:- * Project (4)
:  +- * Filter (3)
:     +- * ColumnarToRow (2)
:        +- Scan parquet default.explain_temp1 (1)
+- BroadcastExchange (9)
   +- * Project (8)
      +- * Filter (7)
         +- * ColumnarToRow (6)
            +- Scan parquet default.explain_temp1 (5)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,10)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 2]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 2]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 10))
     
(4) Project [codegen id : 2]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,10)]
ReadSchema: struct<key:int,val:int>
     
(6) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(7) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 10))
     
(8) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(9) BroadcastExchange 
Input: [key#x, val#x]
     
(10) BroadcastHashJoin [codegen id : 2]
Left keys: List(key#x)
Right keys: List(key#x)
Join condition: None


-- !query 13
EXPLAIN FORMATTED
  WITH cte1 AS (
    SELECT key, max(val)
    FROM explain_temp1 
    WHERE key > 10
    GROUP BY key
  )
  SELECT * FROM cte1 a, cte1 b WHERE a.key = b.key
-- !query 13 schema
struct<plan:string>
-- !query 13 output
== Physical Plan ==
* BroadcastHashJoin Inner BuildRight (11)
:- * HashAggregate (7)
:  +- Exchange (6)
:     +- * HashAggregate (5)
:        +- * Project (4)
:           +- * Filter (3)
:              +- * ColumnarToRow (2)
:                 +- Scan parquet default.explain_temp1 (1)
+- BroadcastExchange (10)
   +- * HashAggregate (9)
      +- ReusedExchange (8)


(1) Scan parquet default.explain_temp1 
Output: [key#x, val#x]
Batched: true
Location [not included in comparison]/{warehouse_dir}/explain_temp1]
PushedFilters: [IsNotNull(key), GreaterThan(key,10)]
ReadSchema: struct<key:int,val:int>
     
(2) ColumnarToRow [codegen id : 1]
Input: [key#x, val#x]
     
(3) Filter [codegen id : 1]
Input     : [key#x, val#x]
Condition : (isnotnull(key#x) AND (key#x > 10))
     
(4) Project [codegen id : 1]
Output    : [key#x, val#x]
Input     : [key#x, val#x]
     
(5) HashAggregate [codegen id : 1]
Input: [key#x, val#x]
     
(6) Exchange 
Input: [key#x, max#x]
     
(7) HashAggregate [codegen id : 4]
Input: [key#x, max#x]
     
(8) ReusedExchange  [Reuses operator id: 6]
Output : ArrayBuffer(key#x, max#x)
     
(9) HashAggregate [codegen id : 3]
Input: [key#x, max#x]
     
(10) BroadcastExchange 
Input: [key#x, max(val)#x]
     
(11) BroadcastHashJoin [codegen id : 4]
Left keys: List(key#x)
Right keys: List(key#x)
Join condition: None


-- !query 14
EXPLAIN FORMATTED
  CREATE VIEW explain_view AS
    SELECT key, val FROM explain_temp1
-- !query 14 schema
struct<plan:string>
-- !query 14 output
== Physical Plan ==
Execute CreateViewCommand (1)
   +- CreateViewCommand (2)
         +- Project (4)
            +- UnresolvedRelation (3)


(1) Execute CreateViewCommand 
Output: []
     
(2) CreateViewCommand 
     
(3) UnresolvedRelation 
     
(4) Project


-- !query 15
DROP TABLE explain_temp1
-- !query 15 schema
struct<>
-- !query 15 output



-- !query 16
DROP TABLE explain_temp2
-- !query 16 schema
struct<>
-- !query 16 output



-- !query 17
DROP TABLE explain_temp3
-- !query 17 schema
struct<>
-- !query 17 output

